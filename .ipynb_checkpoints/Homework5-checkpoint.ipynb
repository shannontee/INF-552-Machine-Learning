{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INF 552 - Homework 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import calinski_harabaz_score\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multi-class and Multi-Label Classification Using Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Download the Anuran Calls (MFCCs) Data Set\n",
    "Choose 70% of the data randomly as the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MFCCs_ 1</th>\n",
       "      <th>MFCCs_ 2</th>\n",
       "      <th>MFCCs_ 3</th>\n",
       "      <th>MFCCs_ 4</th>\n",
       "      <th>MFCCs_ 5</th>\n",
       "      <th>MFCCs_ 6</th>\n",
       "      <th>MFCCs_ 7</th>\n",
       "      <th>MFCCs_ 8</th>\n",
       "      <th>MFCCs_ 9</th>\n",
       "      <th>MFCCs_10</th>\n",
       "      <th>...</th>\n",
       "      <th>MFCCs_17</th>\n",
       "      <th>MFCCs_18</th>\n",
       "      <th>MFCCs_19</th>\n",
       "      <th>MFCCs_20</th>\n",
       "      <th>MFCCs_21</th>\n",
       "      <th>MFCCs_22</th>\n",
       "      <th>Family</th>\n",
       "      <th>Genus</th>\n",
       "      <th>Species</th>\n",
       "      <th>RecordID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152936</td>\n",
       "      <td>-0.105586</td>\n",
       "      <td>0.200722</td>\n",
       "      <td>0.317201</td>\n",
       "      <td>0.260764</td>\n",
       "      <td>0.100945</td>\n",
       "      <td>-0.150063</td>\n",
       "      <td>-0.171128</td>\n",
       "      <td>0.124676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108351</td>\n",
       "      <td>-0.077623</td>\n",
       "      <td>-0.009568</td>\n",
       "      <td>0.057684</td>\n",
       "      <td>0.118680</td>\n",
       "      <td>0.014038</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.171534</td>\n",
       "      <td>-0.098975</td>\n",
       "      <td>0.268425</td>\n",
       "      <td>0.338672</td>\n",
       "      <td>0.268353</td>\n",
       "      <td>0.060835</td>\n",
       "      <td>-0.222475</td>\n",
       "      <td>-0.207693</td>\n",
       "      <td>0.170883</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090974</td>\n",
       "      <td>-0.056510</td>\n",
       "      <td>-0.035303</td>\n",
       "      <td>0.020140</td>\n",
       "      <td>0.082263</td>\n",
       "      <td>0.029056</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152317</td>\n",
       "      <td>-0.082973</td>\n",
       "      <td>0.287128</td>\n",
       "      <td>0.276014</td>\n",
       "      <td>0.189867</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>-0.242234</td>\n",
       "      <td>-0.219153</td>\n",
       "      <td>0.232538</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050691</td>\n",
       "      <td>-0.023590</td>\n",
       "      <td>-0.066722</td>\n",
       "      <td>-0.025083</td>\n",
       "      <td>0.099108</td>\n",
       "      <td>0.077162</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.224392</td>\n",
       "      <td>0.118985</td>\n",
       "      <td>0.329432</td>\n",
       "      <td>0.372088</td>\n",
       "      <td>0.361005</td>\n",
       "      <td>0.015501</td>\n",
       "      <td>-0.194347</td>\n",
       "      <td>-0.098181</td>\n",
       "      <td>0.270375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136009</td>\n",
       "      <td>-0.177037</td>\n",
       "      <td>-0.130498</td>\n",
       "      <td>-0.054766</td>\n",
       "      <td>-0.018691</td>\n",
       "      <td>0.023954</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.087817</td>\n",
       "      <td>-0.068345</td>\n",
       "      <td>0.306967</td>\n",
       "      <td>0.330923</td>\n",
       "      <td>0.249144</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>-0.265423</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>0.266434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048885</td>\n",
       "      <td>-0.053074</td>\n",
       "      <td>-0.088550</td>\n",
       "      <td>-0.031346</td>\n",
       "      <td>0.108610</td>\n",
       "      <td>0.079244</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MFCCs_ 1  MFCCs_ 2  MFCCs_ 3  MFCCs_ 4  MFCCs_ 5  MFCCs_ 6  MFCCs_ 7  \\\n",
       "0       1.0  0.152936 -0.105586  0.200722  0.317201  0.260764  0.100945   \n",
       "1       1.0  0.171534 -0.098975  0.268425  0.338672  0.268353  0.060835   \n",
       "2       1.0  0.152317 -0.082973  0.287128  0.276014  0.189867  0.008714   \n",
       "3       1.0  0.224392  0.118985  0.329432  0.372088  0.361005  0.015501   \n",
       "4       1.0  0.087817 -0.068345  0.306967  0.330923  0.249144  0.006884   \n",
       "\n",
       "   MFCCs_ 8  MFCCs_ 9  MFCCs_10    ...     MFCCs_17  MFCCs_18  MFCCs_19  \\\n",
       "0 -0.150063 -0.171128  0.124676    ...    -0.108351 -0.077623 -0.009568   \n",
       "1 -0.222475 -0.207693  0.170883    ...    -0.090974 -0.056510 -0.035303   \n",
       "2 -0.242234 -0.219153  0.232538    ...    -0.050691 -0.023590 -0.066722   \n",
       "3 -0.194347 -0.098181  0.270375    ...    -0.136009 -0.177037 -0.130498   \n",
       "4 -0.265423 -0.172700  0.266434    ...    -0.048885 -0.053074 -0.088550   \n",
       "\n",
       "   MFCCs_20  MFCCs_21  MFCCs_22           Family      Genus         Species  \\\n",
       "0  0.057684  0.118680  0.014038  Leptodactylidae  Adenomera  AdenomeraAndre   \n",
       "1  0.020140  0.082263  0.029056  Leptodactylidae  Adenomera  AdenomeraAndre   \n",
       "2 -0.025083  0.099108  0.077162  Leptodactylidae  Adenomera  AdenomeraAndre   \n",
       "3 -0.054766 -0.018691  0.023954  Leptodactylidae  Adenomera  AdenomeraAndre   \n",
       "4 -0.031346  0.108610  0.079244  Leptodactylidae  Adenomera  AdenomeraAndre   \n",
       "\n",
       "   RecordID  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Frogs_MFCCs.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, train_size=0.7, test_size = 0.3)\n",
    "\n",
    "X_train = train_df.iloc[:,:-4]\n",
    "y_train = train_df.iloc[:,-4:-1]\n",
    "X_test = test_df.iloc[:,:-4]\n",
    "y_test = test_df.iloc[:,-4:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Solve a multi-class and multi-label problem\n",
    "Each instance has three labels: Families, Genus, and Species. Each of the labels has multiple classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Research exact match and hamming score/ loss methods for evaluating multi-label classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exact Match is the most strict metric for evaluating multi-label classification that indicates the percentage of samples that have all their labels classified correctly.It ignores those partially correct by considering them incorrect and extending the accuracy used in single label case for multi-label prediction. A disadvantage of this measure is that it doesn't distinguish between complete incorrect and partially correct. Exact Match can be found using the accuracy score library in sklearn. The documentation for the library says: in multilabel classification, this function computes subset accuracy: the set of labels predicted for a sample must exactly match the corresponding set of labels in y_true.\n",
    "\n",
    "Hamming Loss reports the fraction of labels that are incorrectly predicted, specifically the fraction of the wrong labels to the total number of labels. It takes into account the prediction error (an incorrect label is predicted) and the missing error (a relevant label not predicted), normalized over total number of classes and total number of examples.\n",
    "\n",
    "https://towardsdatascience.com/journey-to-the-center-of-multi-label-classification-384c40229bff\n",
    "\n",
    "https://stats.stackexchange.com/questions/12702/what-are-the-measure-for-accuracy-of-multilabel-data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Train a SVM for each of the labels, using Gaussian kernels and one versus all classifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Family Label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_family = y_train['Family']\n",
    "\n",
    "gamma = np.linspace(0.01,1000,10)\n",
    "C = np.logspace(-5, 8, 10)\n",
    "\n",
    "parameters = []\n",
    "scores = []\n",
    "\n",
    "# Iterate through each value of gamma and C\n",
    "for g in gamma:\n",
    "    for c in C:      \n",
    "        svm_model = SVC(kernel='rbf', gamma = g, C=c) \n",
    "        svm_model.fit(X_train, y_train_family)\n",
    "        score = svm_model.score(X_train, y_train_family)\n",
    "            \n",
    "        if score >= 0.7:\n",
    "            scores.append(svm_model.score(X_train, y_train_family))\n",
    "            parameters.append((g,c)) # Save values of gamma and C which are above 70% threshold\n",
    "\n",
    "# Perform cross validation on parameters that had above 70% threshold\n",
    "svm_scores = {}\n",
    "for p in parameters:\n",
    "    svm_model = SVC(kernel='rbf', gamma = p[0], C=p[1])\n",
    "    svm_score = cross_val_score(svm_model, X_train, y_train_family, cv=10, scoring=make_scorer(hamming_loss))\n",
    "    svm_scores[p] = np.mean(svm_score)\n",
    "    \n",
    "# Select best parameter\n",
    "min_index = list(svm_scores.values()).index(min(svm_scores.values()))\n",
    "best_parameter = list(svm_scores.keys())[min_index]\n",
    "\n",
    "# Train model using best parameter\n",
    "best_svm_model = SVC(kernel=\"rbf\", gamma=best_parameter[0], C=best_parameter[1])\n",
    "best_svm_model.fit(X_train,y_train_family)\n",
    "pred['Family_1'] = best_svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: gamma = 0.01 and C = 129154.96650148826\n"
     ]
    }
   ],
   "source": [
    "print('Best Parameters: gamma =', best_parameter[0], 'and C =', best_parameter[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9870310328855951\n",
      "Hamming Loss: 0.012968967114404817\n"
     ]
    }
   ],
   "source": [
    "test_score = accuracy_score(y_test['Family'], pred['Family_1'])\n",
    "hamming = hamming_loss(y_test['Family'], pred['Family_1'])\n",
    "print('Accuracy Score:', test_score)\n",
    "print('Hamming Loss:', hamming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first implementation, that I did above, iterated through all combinations for gamma and C and saved those that had a train accuracy over 70%. I performed a 10 fold cross validation using cross_val_score on those saved parameters to find the best parameter then tested the best model on test set. Using this method, I found the best parameter and corresponding hamming loss was same as using GridSearchCV (as shown below). Therefore, for the remaining of the problems, I used GridSearchCV since it was simpler and shorter to implement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': np.logspace(-5, 8, 10), 'gamma': np.linspace(0.01,1000,10)}\n",
    "svm_model = SVC(kernel='rbf')\n",
    "grid = GridSearchCV(svm_model, param_grid=param_grid, cv=10, scoring = 'accuracy') \n",
    "grid.fit(X_train, y_train['Family'])\n",
    "family_params = grid.best_params_\n",
    "family_score = grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 129154.96650148826, 'gamma': 0.01}\n",
      "Best Score: 0.9833200953137411\n"
     ]
    }
   ],
   "source": [
    "print('Best Parameters:', family_params)\n",
    "print('Best Score:', family_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9870310328855951\n",
      "Hamming Loss: 0.012968967114404817\n"
     ]
    }
   ],
   "source": [
    "pred['Family'] = grid.predict(X_test)\n",
    "test_score = accuracy_score(y_test['Family'], pred['Family'])\n",
    "hamming = hamming_loss(y_test['Family'], pred['Family'])\n",
    "\n",
    "print('Accuracy Score:', test_score)\n",
    "print('Hamming Loss:', hamming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genus Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': np.logspace(-5, 8, 10), 'gamma': np.linspace(0.01,1000,10)}\n",
    "svm_model = SVC(kernel='rbf')\n",
    "grid = GridSearchCV(svm_model, param_grid=param_grid, cv=10, scoring = 'accuracy') \n",
    "grid.fit(X_train, y_train['Genus'])\n",
    "genus_params = grid.best_params_\n",
    "genus_score = grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 3593813.6638046256, 'gamma': 0.01}\n",
      "Best Score: 0.9847100873709294\n"
     ]
    }
   ],
   "source": [
    "print('Best Parameters:', genus_params)\n",
    "print('Best Score:', genus_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9833256137100509\n",
      "Hamming Loss: 0.01667438628994905\n"
     ]
    }
   ],
   "source": [
    "pred['Genus'] = grid.predict(X_test)\n",
    "test_score = accuracy_score(y_test['Genus'], pred['Genus'])\n",
    "hamming = hamming_loss(y_test['Genus'], pred['Genus'])\n",
    "\n",
    "print('Accuracy Score:', test_score)\n",
    "print('Hamming Loss:', hamming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Species Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': np.logspace(-5, 8, 10), 'gamma': np.linspace(0.01,1000,10)}\n",
    "svm_model = SVC(kernel='rbf')\n",
    "grid = GridSearchCV(svm_model, param_grid=param_grid, cv=10, scoring = 'accuracy')\n",
    "grid.fit(X_train, y_train['Species'])\n",
    "\n",
    "species_params = grid.best_params_\n",
    "species_score = grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 129154.96650148826, 'gamma': 0.01}\n",
      "Best Score: 0.9845115170770453\n"
     ]
    }
   ],
   "source": [
    "print('Best Parameters:', species_params)\n",
    "print('Best Score:', species_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9777674849467346\n",
      "Hamming Loss: 0.0222325150532654\n"
     ]
    }
   ],
   "source": [
    "pred['Species'] = grid.predict(X_test)\n",
    "test_score = accuracy_score(y_test['Species'], pred['Species'])\n",
    "hamming = hamming_loss(y_test['Species'], pred['Species'])\n",
    "\n",
    "print('Accuracy Score:', test_score)\n",
    "print('Hamming Loss:', hamming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii. Repeat 1(b)ii with L1-penalized SVMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_l1 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the attributes\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Family Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': np.logspace(-5, 8, 10)}\n",
    "l1_svm = LinearSVC(penalty= 'l1', dual=False, max_iter = 5000)\n",
    "grid = GridSearchCV(l1_svm, param_grid=param_grid, cv=10, scoring = 'accuracy') \n",
    "grid.fit(scaled_X_train, y_train['Family'])\n",
    "\n",
    "l1_family_params = grid.best_params_\n",
    "l1_family_score = grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 166.81005372000593}\n",
      "Best Score: 0.9352660841938046\n"
     ]
    }
   ],
   "source": [
    "print('Best Parameters:', l1_family_params)\n",
    "print('Best Score:', l1_family_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9383974062065771\n",
      "Hamming Loss: 0.06160259379342288\n"
     ]
    }
   ],
   "source": [
    "pred_l1['Family'] = grid.predict(scaled_X_test)\n",
    "test_score = accuracy_score(y_test['Family'], pred_l1['Family'])\n",
    "hamming = hamming_loss(y_test['Family'], pred_l1['Family'])\n",
    "\n",
    "print('Accuracy Score:', test_score)\n",
    "print('Hamming Loss:', hamming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genus Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': np.logspace(-5, 8, 10)}\n",
    "l1_svm = LinearSVC(penalty= 'l1', dual=False, max_iter = 5000)\n",
    "grid = GridSearchCV(l1_svm, param_grid=param_grid, cv=10, scoring='accuracy') \n",
    "grid.fit(scaled_X_train, y_train['Genus'])\n",
    "\n",
    "l1_genus_params = grid.best_params_\n",
    "l1_genus_score = grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 5.994842503189409}\n",
      "Best Score: 0.9501588562351072\n"
     ]
    }
   ],
   "source": [
    "print('Best Parameters:', l1_genus_params)\n",
    "print('Best Score:', l1_genus_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.951366373320982\n",
      "Hamming Loss: 0.04863362667901806\n"
     ]
    }
   ],
   "source": [
    "pred_l1['Genus'] = grid.predict(scaled_X_test)\n",
    "test_score = accuracy_score(y_test['Genus'], pred_l1['Genus'])\n",
    "hamming = hamming_loss(y_test['Genus'], pred_l1['Genus'])\n",
    "\n",
    "print('Accuracy Score:', test_score)\n",
    "print('Hamming Loss:', hamming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Species Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': np.logspace(-5, 8, 10)}\n",
    "l1_svm = LinearSVC(penalty= 'l1', dual=False, max_iter = 5000)\n",
    "grid = GridSearchCV(l1_svm, param_grid=param_grid, cv=10, scoring = 'accuracy') \n",
    "grid.fit(scaled_X_train, y_train['Species'])\n",
    "\n",
    "l1_species_params = grid.best_params_\n",
    "l1_species_score = grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 5.994842503189409}\n",
      "Best Score: 0.9571088165210484\n"
     ]
    }
   ],
   "source": [
    "print('Best Parameters:', l1_species_params)\n",
    "print('Best Score:', l1_species_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9583140342751274\n",
      "Hamming Loss: 0.041685965724872626\n"
     ]
    }
   ],
   "source": [
    "pred_l1['Species'] = grid.predict(scaled_X_test)\n",
    "test_score = accuracy_score(y_test['Species'], pred_l1['Species'])\n",
    "hamming = hamming_loss(y_test['Species'], pred_l1['Species'])\n",
    "\n",
    "print('Accuracy Score:', test_score)\n",
    "print('Hamming Loss:', hamming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iv. Repeat 1(b)iii by using SMOTE or any other method you know to remedy class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_smote = pd.DataFrame()\n",
    "sm = SMOTE()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Family Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res, y_res = sm.fit_sample(scaled_X_train, y_train['Family'])\n",
    "X_res_family = pd.DataFrame(X_res)\n",
    "Y_res_family = pd.DataFrame(y_res)\n",
    "\n",
    "param_grid = {'C': np.logspace(-5, 8, 10)}\n",
    "l1_svm = LinearSVC(penalty= 'l1', dual=False, max_iter = 5000)\n",
    "grid = GridSearchCV(l1_svm, param_grid=param_grid, cv=10, scoring = 'accuracy') \n",
    "grid.fit(X_res_family, Y_res_family)\n",
    "\n",
    "smote_family_params = grid.best_params_\n",
    "smote_family_score = grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 129154.96650148826}\n",
      "Best Score: 0.9523886378308586\n"
     ]
    }
   ],
   "source": [
    "print('Best Parameters:', smote_family_params)\n",
    "print('Best Score:', smote_family_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9194071329319129\n",
      "Hamming Loss: 0.08059286706808708\n"
     ]
    }
   ],
   "source": [
    "pred_smote['Family'] = grid.predict(scaled_X_test)\n",
    "test_score = accuracy_score(y_test['Family'], pred_smote['Family'])\n",
    "hamming = hamming_loss(y_test['Family'], pred_smote['Family'])\n",
    "\n",
    "print('Accuracy Score:', test_score)\n",
    "print('Hamming Loss:', hamming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genus Label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res, y_res = sm.fit_sample(scaled_X_train, y_train['Genus'])\n",
    "X_res_genus = pd.DataFrame(X_res)\n",
    "Y_res_genus = pd.DataFrame(y_res)\n",
    "\n",
    "param_grid = { 'C': np.logspace(-5, 8, 10)}\n",
    "l1_svm = LinearSVC(penalty= 'l1', dual=False, max_iter = 5000)\n",
    "grid = GridSearchCV(l1_svm, param_grid=param_grid, cv=10, scoring = 'accuracy') \n",
    "grid.fit(X_res_genus, Y_res_genus)\n",
    "\n",
    "smote_genus_params = grid.best_params_\n",
    "smote_genus_score = grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 166.81005372000593}\n",
      "Best Score: 0.9603031860226104\n"
     ]
    }
   ],
   "source": [
    "print('Best Parameters:', smote_genus_params)\n",
    "print('Best Score:', smote_genus_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9166280685502547\n",
      "Hamming Loss: 0.08337193144974525\n"
     ]
    }
   ],
   "source": [
    "pred_smote['Genus'] = grid.predict(scaled_X_test)\n",
    "test_score = accuracy_score(y_test['Genus'], pred_smote['Genus'])\n",
    "hamming = hamming_loss(y_test['Genus'], pred_smote['Genus'])\n",
    "\n",
    "print('Accuracy Score:', test_score)\n",
    "print('Hamming Loss:', hamming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Species Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res, y_res = sm.fit_sample(scaled_X_train, y_train['Species'])\n",
    "X_res_species = pd.DataFrame(X_res)\n",
    "Y_res_species = pd.DataFrame(y_res)\n",
    "\n",
    "param_grid = {'C': np.logspace(-5, 8, 10)}\n",
    "l1_svm = LinearSVC(penalty= 'l1', dual=False, max_iter = 5000)\n",
    "grid = GridSearchCV(l1_svm, param_grid=param_grid, cv=10, scoring = 'accuracy') \n",
    "grid.fit(X_res_species, Y_res_species)\n",
    "\n",
    "smote_species_params = grid.best_params_\n",
    "smote_species_score = grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 129154.96650148826}\n",
      "Best Score: 0.9621599675192855\n"
     ]
    }
   ],
   "source": [
    "print('Best Parameters:', smote_species_params)\n",
    "print('Best Score:', smote_species_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.952292728114868\n",
      "Hamming Loss: 0.047707271885132005\n"
     ]
    }
   ],
   "source": [
    "pred_smote['Species'] = grid.predict(scaled_X_test)\n",
    "test_score = accuracy_score(y_test['Species'], pred_smote['Species'])\n",
    "hamming = hamming_loss(y_test['Species'], pred_smote['Species'])\n",
    "\n",
    "print('Accuracy Score:', test_score)\n",
    "print('Hamming Loss:', hamming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report your conclusions about the classifiers you trained.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b)ii: Gaussian Kernel SVM:\n",
    "\n",
    "|                 |  Family |  Genus   | Species |\n",
    "|-----------------|---------|----------|---------|\n",
    "|  Best Gamma     |  0.01   |  0.01    |  0.01   |\n",
    "|  Best C         |129154.96|3593813.66|129154.96|\n",
    "|  Best Score     |  0.983  |  0.9847  | 0.9845  |\n",
    "|                 |         |          |         |\n",
    "|  Accuracy Score |  0.987  |  0.983   | 0.977   |\n",
    "|  Hamming Loss   |  0.013  |  0.017   | 0.023   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b)iii: L1-penalized SVMs:\n",
    "\n",
    "|                 |  Family |  Genus   | Species |\n",
    "|-----------------|---------|----------|---------|\n",
    "|  Best C         |  166.81 |   5.99   |  5.99   |\n",
    "|  Best Score     |  0.935  |   0.950  |  0.957  |\n",
    "|                 |         |          |         |\n",
    "|  Accuracy Score |  0.938  |   0.951  |  0.958  |\n",
    "|  Hamming Loss   |  0.062  |   0.049  |  0.042  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b)iv: L1-penalized SVMs with SMOTE:\n",
    "\n",
    "|                 |  Family |  Genus   | Species |\n",
    "|-----------------|---------|----------|---------|\n",
    "|  Best C         |129154.96|  166.81  |129154.96|\n",
    "|  Best Score     |  0.952  |   0.960  |  0.962  |\n",
    "|                 |         |          |         |\n",
    "|  Accuracy Score |  0.919  |   0.917  |  0.952  |\n",
    "|  Hamming Loss   |  0.081  |   0.083  |  0.048  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the tables above, C is the weight of the SVM parameter and gamma is the width of the Gaussian Kernel. The SVM using Gaussian Kernels had the best the Accuracy Score and Hamming Loss. Therefore, this non-linear SVM performed better than the L1-penalized SVMs. Using SMOTE to remedy class imbalance did not improve the L1-penalized SVM model. Based on the Accuracy Scores and Hamming Loss for the three classifiers trained, the dataset is probably not linearly separated and was able to fit better with a non-linear model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K-Means Clustering on a Multi-Class and Multi-Label Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means_clustering():\n",
    "    cluster_df = pd.read_csv('Frogs_MFCCs.csv')\n",
    "    X_df = cluster_df.iloc[:,:-4]\n",
    "\n",
    "    # Started with K=2 because can't compute CH score for K=1 due to denominator will be 0 if K=1\n",
    "    k_list = list(range(2,51)) \n",
    "\n",
    "    # Choose K automatically using CH score\n",
    "    k_scores_CH = []\n",
    "\n",
    "    for k in k_list: \n",
    "        kmeans = KMeans(n_clusters=k)\n",
    "        kmeans.fit(X_df)  \n",
    "        k_labels = kmeans.labels_\n",
    "        CH = calinski_harabaz_score(X_df, k_labels)\n",
    "        k_scores_CH.append(CH)\n",
    "\n",
    "    opt_k_CH = k_list[k_scores_CH.index(max(k_scores_CH))]\n",
    "\n",
    "    kmeans = KMeans(n_clusters=opt_k_CH).fit(X_df)\n",
    "    cluster_df['cluster'] = kmeans.labels_\n",
    "\n",
    "    # Determine family, genius, and species majority by reading the true labels for each cluster\n",
    "    for c in range(0,opt_k_CH):\n",
    "        family = cluster_df[cluster_df.cluster == c]['Family'].value_counts().index[0]\n",
    "        cluster_df.loc[cluster_df.cluster == c, 'Family_Majority'] = family\n",
    "\n",
    "        genus = cluster_df[cluster_df.cluster == c]['Genus'].value_counts().index[0]\n",
    "        cluster_df.loc[cluster_df.cluster == c, 'Genus_Majority'] = genus\n",
    "\n",
    "        species = cluster_df[cluster_df.cluster == c]['Species'].value_counts().index[0]\n",
    "        cluster_df.loc[cluster_df.cluster == c, 'Species_Majority'] = species\n",
    "\n",
    "    # Calculate Hamming loss between the true labels and the labels assigned by clusters\n",
    "    scores = []\n",
    "    labels = ['Family', 'Genus', 'Species']\n",
    "\n",
    "    for c in range(0,opt_k_CH):\n",
    "        \n",
    "        cluster_scores = []\n",
    "        cluster = cluster_df[cluster_df.cluster == c]\n",
    "        for l in labels:\n",
    "            cluster_label = l + '_Majority'\n",
    "\n",
    "            score = hamming_loss(cluster[l], cluster[cluster_label])\n",
    "            cluster_scores.append(score)\n",
    "            print('Cluster %d, %s: %f' %(c, l, score))\n",
    "            \n",
    "        avg_cluster_loss = np.mean(cluster_scores)\n",
    "        scores.append(avg_cluster_loss)\n",
    "        print('Average for Cluster %d: %f' %(c,avg_cluster_loss))\n",
    "        \n",
    "    avg_loss = np.mean(scores)\n",
    "    print('Average for iteration:', avg_loss)\n",
    "\n",
    "    return(avg_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte-Carlo Simulation \n",
    "Perform the following procedures 50 times, and report the average and standard deviation of the 50 Hamming Distances that you calculate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1:\n",
      "Cluster 0, Family: 0.034464\n",
      "Cluster 0, Genus: 0.035575\n",
      "Cluster 0, Species: 0.035575\n",
      "Average for Cluster 0: 0.035205\n",
      "Cluster 1, Family: 0.432583\n",
      "Cluster 1, Genus: 0.561023\n",
      "Cluster 1, Species: 0.692244\n",
      "Average for Cluster 1: 0.561950\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 2:\n",
      "Cluster 0, Family: 0.034464\n",
      "Cluster 0, Genus: 0.035575\n",
      "Cluster 0, Species: 0.035575\n",
      "Average for Cluster 0: 0.035205\n",
      "Cluster 1, Family: 0.432583\n",
      "Cluster 1, Genus: 0.561023\n",
      "Cluster 1, Species: 0.692244\n",
      "Average for Cluster 1: 0.561950\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 3:\n",
      "Cluster 0, Family: 0.432583\n",
      "Cluster 0, Genus: 0.561023\n",
      "Cluster 0, Species: 0.692244\n",
      "Average for Cluster 0: 0.561950\n",
      "Cluster 1, Family: 0.034464\n",
      "Cluster 1, Genus: 0.035575\n",
      "Cluster 1, Species: 0.035575\n",
      "Average for Cluster 1: 0.035205\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 4:\n",
      "Cluster 0, Family: 0.432583\n",
      "Cluster 0, Genus: 0.561023\n",
      "Cluster 0, Species: 0.692244\n",
      "Average for Cluster 0: 0.561950\n",
      "Cluster 1, Family: 0.034464\n",
      "Cluster 1, Genus: 0.035575\n",
      "Cluster 1, Species: 0.035575\n",
      "Average for Cluster 1: 0.035205\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 5:\n",
      "Cluster 0, Family: 0.432583\n",
      "Cluster 0, Genus: 0.561023\n",
      "Cluster 0, Species: 0.692244\n",
      "Average for Cluster 0: 0.561950\n",
      "Cluster 1, Family: 0.034464\n",
      "Cluster 1, Genus: 0.035575\n",
      "Cluster 1, Species: 0.035575\n",
      "Average for Cluster 1: 0.035205\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 6:\n",
      "Cluster 0, Family: 0.034464\n",
      "Cluster 0, Genus: 0.035575\n",
      "Cluster 0, Species: 0.035575\n",
      "Average for Cluster 0: 0.035205\n",
      "Cluster 1, Family: 0.432583\n",
      "Cluster 1, Genus: 0.561023\n",
      "Cluster 1, Species: 0.692244\n",
      "Average for Cluster 1: 0.561950\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 7:\n",
      "Cluster 0, Family: 0.034464\n",
      "Cluster 0, Genus: 0.035575\n",
      "Cluster 0, Species: 0.035575\n",
      "Average for Cluster 0: 0.035205\n",
      "Cluster 1, Family: 0.432583\n",
      "Cluster 1, Genus: 0.561023\n",
      "Cluster 1, Species: 0.692244\n",
      "Average for Cluster 1: 0.561950\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 8:\n",
      "Cluster 0, Family: 0.432583\n",
      "Cluster 0, Genus: 0.561023\n",
      "Cluster 0, Species: 0.692244\n",
      "Average for Cluster 0: 0.561950\n",
      "Cluster 1, Family: 0.034464\n",
      "Cluster 1, Genus: 0.035575\n",
      "Cluster 1, Species: 0.035575\n",
      "Average for Cluster 1: 0.035205\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 9:\n",
      "Cluster 0, Family: 0.432583\n",
      "Cluster 0, Genus: 0.561023\n",
      "Cluster 0, Species: 0.692244\n",
      "Average for Cluster 0: 0.561950\n",
      "Cluster 1, Family: 0.034464\n",
      "Cluster 1, Genus: 0.035575\n",
      "Cluster 1, Species: 0.035575\n",
      "Average for Cluster 1: 0.035205\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 10:\n",
      "Cluster 0, Family: 0.432583\n",
      "Cluster 0, Genus: 0.561023\n",
      "Cluster 0, Species: 0.692244\n",
      "Average for Cluster 0: 0.561950\n",
      "Cluster 1, Family: 0.034464\n",
      "Cluster 1, Genus: 0.035575\n",
      "Cluster 1, Species: 0.035575\n",
      "Average for Cluster 1: 0.035205\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 11:\n",
      "Cluster 0, Family: 0.034464\n",
      "Cluster 0, Genus: 0.035575\n",
      "Cluster 0, Species: 0.035575\n",
      "Average for Cluster 0: 0.035205\n",
      "Cluster 1, Family: 0.432583\n",
      "Cluster 1, Genus: 0.561023\n",
      "Cluster 1, Species: 0.692244\n",
      "Average for Cluster 1: 0.561950\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 12:\n",
      "Cluster 0, Family: 0.432583\n",
      "Cluster 0, Genus: 0.561023\n",
      "Cluster 0, Species: 0.692244\n",
      "Average for Cluster 0: 0.561950\n",
      "Cluster 1, Family: 0.034464\n",
      "Cluster 1, Genus: 0.035575\n",
      "Cluster 1, Species: 0.035575\n",
      "Average for Cluster 1: 0.035205\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 13:\n",
      "Cluster 0, Family: 0.432583\n",
      "Cluster 0, Genus: 0.561023\n",
      "Cluster 0, Species: 0.692244\n",
      "Average for Cluster 0: 0.561950\n",
      "Cluster 1, Family: 0.034464\n",
      "Cluster 1, Genus: 0.035575\n",
      "Cluster 1, Species: 0.035575\n",
      "Average for Cluster 1: 0.035205\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 14:\n",
      "Cluster 0, Family: 0.432583\n",
      "Cluster 0, Genus: 0.561023\n",
      "Cluster 0, Species: 0.692244\n",
      "Average for Cluster 0: 0.561950\n",
      "Cluster 1, Family: 0.034464\n",
      "Cluster 1, Genus: 0.035575\n",
      "Cluster 1, Species: 0.035575\n",
      "Average for Cluster 1: 0.035205\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 15:\n",
      "Cluster 0, Family: 0.432583\n",
      "Cluster 0, Genus: 0.561023\n",
      "Cluster 0, Species: 0.692244\n",
      "Average for Cluster 0: 0.561950\n",
      "Cluster 1, Family: 0.034464\n",
      "Cluster 1, Genus: 0.035575\n",
      "Cluster 1, Species: 0.035575\n",
      "Average for Cluster 1: 0.035205\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 16:\n",
      "Cluster 0, Family: 0.432583\n",
      "Cluster 0, Genus: 0.561023\n",
      "Cluster 0, Species: 0.692244\n",
      "Average for Cluster 0: 0.561950\n",
      "Cluster 1, Family: 0.034464\n",
      "Cluster 1, Genus: 0.035575\n",
      "Cluster 1, Species: 0.035575\n",
      "Average for Cluster 1: 0.035205\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 17:\n",
      "Cluster 0, Family: 0.034464\n",
      "Cluster 0, Genus: 0.035575\n",
      "Cluster 0, Species: 0.035575\n",
      "Average for Cluster 0: 0.035205\n",
      "Cluster 1, Family: 0.432583\n",
      "Cluster 1, Genus: 0.561023\n",
      "Cluster 1, Species: 0.692244\n",
      "Average for Cluster 1: 0.561950\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 18:\n",
      "Cluster 0, Family: 0.034464\n",
      "Cluster 0, Genus: 0.035575\n",
      "Cluster 0, Species: 0.035575\n",
      "Average for Cluster 0: 0.035205\n",
      "Cluster 1, Family: 0.432583\n",
      "Cluster 1, Genus: 0.561023\n",
      "Cluster 1, Species: 0.692244\n",
      "Average for Cluster 1: 0.561950\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 19:\n",
      "Cluster 0, Family: 0.034464\n",
      "Cluster 0, Genus: 0.035575\n",
      "Cluster 0, Species: 0.035575\n",
      "Average for Cluster 0: 0.035205\n",
      "Cluster 1, Family: 0.432583\n",
      "Cluster 1, Genus: 0.561023\n",
      "Cluster 1, Species: 0.692244\n",
      "Average for Cluster 1: 0.561950\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 20:\n",
      "Cluster 0, Family: 0.432583\n",
      "Cluster 0, Genus: 0.561023\n",
      "Cluster 0, Species: 0.692244\n",
      "Average for Cluster 0: 0.561950\n",
      "Cluster 1, Family: 0.034464\n",
      "Cluster 1, Genus: 0.035575\n",
      "Cluster 1, Species: 0.035575\n",
      "Average for Cluster 1: 0.035205\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 21:\n",
      "Cluster 0, Family: 0.034464\n",
      "Cluster 0, Genus: 0.035575\n",
      "Cluster 0, Species: 0.035575\n",
      "Average for Cluster 0: 0.035205\n",
      "Cluster 1, Family: 0.432583\n",
      "Cluster 1, Genus: 0.561023\n",
      "Cluster 1, Species: 0.692244\n",
      "Average for Cluster 1: 0.561950\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 22:\n",
      "Cluster 0, Family: 0.432583\n",
      "Cluster 0, Genus: 0.561023\n",
      "Cluster 0, Species: 0.692244\n",
      "Average for Cluster 0: 0.561950\n",
      "Cluster 1, Family: 0.034464\n",
      "Cluster 1, Genus: 0.035575\n",
      "Cluster 1, Species: 0.035575\n",
      "Average for Cluster 1: 0.035205\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 23:\n",
      "Cluster 0, Family: 0.034464\n",
      "Cluster 0, Genus: 0.035575\n",
      "Cluster 0, Species: 0.035575\n",
      "Average for Cluster 0: 0.035205\n",
      "Cluster 1, Family: 0.432583\n",
      "Cluster 1, Genus: 0.561023\n",
      "Cluster 1, Species: 0.692244\n",
      "Average for Cluster 1: 0.561950\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 24:\n",
      "Cluster 0, Family: 0.432583\n",
      "Cluster 0, Genus: 0.561023\n",
      "Cluster 0, Species: 0.692244\n",
      "Average for Cluster 0: 0.561950\n",
      "Cluster 1, Family: 0.034464\n",
      "Cluster 1, Genus: 0.035575\n",
      "Cluster 1, Species: 0.035575\n",
      "Average for Cluster 1: 0.035205\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 25:\n",
      "Cluster 0, Family: 0.432583\n",
      "Cluster 0, Genus: 0.561023\n",
      "Cluster 0, Species: 0.692244\n",
      "Average for Cluster 0: 0.561950\n",
      "Cluster 1, Family: 0.034464\n",
      "Cluster 1, Genus: 0.035575\n",
      "Cluster 1, Species: 0.035575\n",
      "Average for Cluster 1: 0.035205\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 26:\n",
      "Cluster 0, Family: 0.034464\n",
      "Cluster 0, Genus: 0.035575\n",
      "Cluster 0, Species: 0.035575\n",
      "Average for Cluster 0: 0.035205\n",
      "Cluster 1, Family: 0.432583\n",
      "Cluster 1, Genus: 0.561023\n",
      "Cluster 1, Species: 0.692244\n",
      "Average for Cluster 1: 0.561950\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 27:\n",
      "Cluster 0, Family: 0.432583\n",
      "Cluster 0, Genus: 0.561023\n",
      "Cluster 0, Species: 0.692244\n",
      "Average for Cluster 0: 0.561950\n",
      "Cluster 1, Family: 0.034464\n",
      "Cluster 1, Genus: 0.035575\n",
      "Cluster 1, Species: 0.035575\n",
      "Average for Cluster 1: 0.035205\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 28:\n",
      "Cluster 0, Family: 0.432583\n",
      "Cluster 0, Genus: 0.561023\n",
      "Cluster 0, Species: 0.692244\n",
      "Average for Cluster 0: 0.561950\n",
      "Cluster 1, Family: 0.034464\n",
      "Cluster 1, Genus: 0.035575\n",
      "Cluster 1, Species: 0.035575\n",
      "Average for Cluster 1: 0.035205\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 29:\n",
      "Cluster 0, Family: 0.432583\n",
      "Cluster 0, Genus: 0.561023\n",
      "Cluster 0, Species: 0.692244\n",
      "Average for Cluster 0: 0.561950\n",
      "Cluster 1, Family: 0.034464\n",
      "Cluster 1, Genus: 0.035575\n",
      "Cluster 1, Species: 0.035575\n",
      "Average for Cluster 1: 0.035205\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 30:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0, Family: 0.034464\n",
      "Cluster 0, Genus: 0.035575\n",
      "Cluster 0, Species: 0.035575\n",
      "Average for Cluster 0: 0.035205\n",
      "Cluster 1, Family: 0.432583\n",
      "Cluster 1, Genus: 0.561023\n",
      "Cluster 1, Species: 0.692244\n",
      "Average for Cluster 1: 0.561950\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 31:\n",
      "Cluster 0, Family: 0.432583\n",
      "Cluster 0, Genus: 0.561023\n",
      "Cluster 0, Species: 0.692244\n",
      "Average for Cluster 0: 0.561950\n",
      "Cluster 1, Family: 0.034464\n",
      "Cluster 1, Genus: 0.035575\n",
      "Cluster 1, Species: 0.035575\n",
      "Average for Cluster 1: 0.035205\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 32:\n",
      "Cluster 0, Family: 0.432583\n",
      "Cluster 0, Genus: 0.561023\n",
      "Cluster 0, Species: 0.692244\n",
      "Average for Cluster 0: 0.561950\n",
      "Cluster 1, Family: 0.034464\n",
      "Cluster 1, Genus: 0.035575\n",
      "Cluster 1, Species: 0.035575\n",
      "Average for Cluster 1: 0.035205\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 33:\n",
      "Cluster 0, Family: 0.432583\n",
      "Cluster 0, Genus: 0.561023\n",
      "Cluster 0, Species: 0.692244\n",
      "Average for Cluster 0: 0.561950\n",
      "Cluster 1, Family: 0.034464\n",
      "Cluster 1, Genus: 0.035575\n",
      "Cluster 1, Species: 0.035575\n",
      "Average for Cluster 1: 0.035205\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 34:\n",
      "Cluster 0, Family: 0.034464\n",
      "Cluster 0, Genus: 0.035575\n",
      "Cluster 0, Species: 0.035575\n",
      "Average for Cluster 0: 0.035205\n",
      "Cluster 1, Family: 0.432583\n",
      "Cluster 1, Genus: 0.561023\n",
      "Cluster 1, Species: 0.692244\n",
      "Average for Cluster 1: 0.561950\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 35:\n",
      "Cluster 0, Family: 0.432583\n",
      "Cluster 0, Genus: 0.561023\n",
      "Cluster 0, Species: 0.692244\n",
      "Average for Cluster 0: 0.561950\n",
      "Cluster 1, Family: 0.034464\n",
      "Cluster 1, Genus: 0.035575\n",
      "Cluster 1, Species: 0.035575\n",
      "Average for Cluster 1: 0.035205\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 36:\n",
      "Cluster 0, Family: 0.432583\n",
      "Cluster 0, Genus: 0.561023\n",
      "Cluster 0, Species: 0.692244\n",
      "Average for Cluster 0: 0.561950\n",
      "Cluster 1, Family: 0.034464\n",
      "Cluster 1, Genus: 0.035575\n",
      "Cluster 1, Species: 0.035575\n",
      "Average for Cluster 1: 0.035205\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 37:\n",
      "Cluster 0, Family: 0.034464\n",
      "Cluster 0, Genus: 0.035575\n",
      "Cluster 0, Species: 0.035575\n",
      "Average for Cluster 0: 0.035205\n",
      "Cluster 1, Family: 0.432583\n",
      "Cluster 1, Genus: 0.561023\n",
      "Cluster 1, Species: 0.692244\n",
      "Average for Cluster 1: 0.561950\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 38:\n",
      "Cluster 0, Family: 0.034464\n",
      "Cluster 0, Genus: 0.035575\n",
      "Cluster 0, Species: 0.035575\n",
      "Average for Cluster 0: 0.035205\n",
      "Cluster 1, Family: 0.432583\n",
      "Cluster 1, Genus: 0.561023\n",
      "Cluster 1, Species: 0.692244\n",
      "Average for Cluster 1: 0.561950\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 39:\n",
      "Cluster 0, Family: 0.034464\n",
      "Cluster 0, Genus: 0.035575\n",
      "Cluster 0, Species: 0.035575\n",
      "Average for Cluster 0: 0.035205\n",
      "Cluster 1, Family: 0.432583\n",
      "Cluster 1, Genus: 0.561023\n",
      "Cluster 1, Species: 0.692244\n",
      "Average for Cluster 1: 0.561950\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 40:\n",
      "Cluster 0, Family: 0.034464\n",
      "Cluster 0, Genus: 0.035575\n",
      "Cluster 0, Species: 0.035575\n",
      "Average for Cluster 0: 0.035205\n",
      "Cluster 1, Family: 0.432583\n",
      "Cluster 1, Genus: 0.561023\n",
      "Cluster 1, Species: 0.692244\n",
      "Average for Cluster 1: 0.561950\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 41:\n",
      "Cluster 0, Family: 0.034464\n",
      "Cluster 0, Genus: 0.035575\n",
      "Cluster 0, Species: 0.035575\n",
      "Average for Cluster 0: 0.035205\n",
      "Cluster 1, Family: 0.432583\n",
      "Cluster 1, Genus: 0.561023\n",
      "Cluster 1, Species: 0.692244\n",
      "Average for Cluster 1: 0.561950\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 42:\n",
      "Cluster 0, Family: 0.034464\n",
      "Cluster 0, Genus: 0.035575\n",
      "Cluster 0, Species: 0.035575\n",
      "Average for Cluster 0: 0.035205\n",
      "Cluster 1, Family: 0.432583\n",
      "Cluster 1, Genus: 0.561023\n",
      "Cluster 1, Species: 0.692244\n",
      "Average for Cluster 1: 0.561950\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 43:\n",
      "Cluster 0, Family: 0.034464\n",
      "Cluster 0, Genus: 0.035575\n",
      "Cluster 0, Species: 0.035575\n",
      "Average for Cluster 0: 0.035205\n",
      "Cluster 1, Family: 0.432583\n",
      "Cluster 1, Genus: 0.561023\n",
      "Cluster 1, Species: 0.692244\n",
      "Average for Cluster 1: 0.561950\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 44:\n",
      "Cluster 0, Family: 0.034464\n",
      "Cluster 0, Genus: 0.035575\n",
      "Cluster 0, Species: 0.035575\n",
      "Average for Cluster 0: 0.035205\n",
      "Cluster 1, Family: 0.432583\n",
      "Cluster 1, Genus: 0.561023\n",
      "Cluster 1, Species: 0.692244\n",
      "Average for Cluster 1: 0.561950\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 45:\n",
      "Cluster 0, Family: 0.034464\n",
      "Cluster 0, Genus: 0.035575\n",
      "Cluster 0, Species: 0.035575\n",
      "Average for Cluster 0: 0.035205\n",
      "Cluster 1, Family: 0.432583\n",
      "Cluster 1, Genus: 0.561023\n",
      "Cluster 1, Species: 0.692244\n",
      "Average for Cluster 1: 0.561950\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 46:\n",
      "Cluster 0, Family: 0.432583\n",
      "Cluster 0, Genus: 0.561023\n",
      "Cluster 0, Species: 0.692244\n",
      "Average for Cluster 0: 0.561950\n",
      "Cluster 1, Family: 0.034464\n",
      "Cluster 1, Genus: 0.035575\n",
      "Cluster 1, Species: 0.035575\n",
      "Average for Cluster 1: 0.035205\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 47:\n",
      "Cluster 0, Family: 0.432583\n",
      "Cluster 0, Genus: 0.561023\n",
      "Cluster 0, Species: 0.692244\n",
      "Average for Cluster 0: 0.561950\n",
      "Cluster 1, Family: 0.034464\n",
      "Cluster 1, Genus: 0.035575\n",
      "Cluster 1, Species: 0.035575\n",
      "Average for Cluster 1: 0.035205\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 48:\n",
      "Cluster 0, Family: 0.432583\n",
      "Cluster 0, Genus: 0.561023\n",
      "Cluster 0, Species: 0.692244\n",
      "Average for Cluster 0: 0.561950\n",
      "Cluster 1, Family: 0.034464\n",
      "Cluster 1, Genus: 0.035575\n",
      "Cluster 1, Species: 0.035575\n",
      "Average for Cluster 1: 0.035205\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 49:\n",
      "Cluster 0, Family: 0.432583\n",
      "Cluster 0, Genus: 0.561023\n",
      "Cluster 0, Species: 0.692244\n",
      "Average for Cluster 0: 0.561950\n",
      "Cluster 1, Family: 0.034464\n",
      "Cluster 1, Genus: 0.035575\n",
      "Cluster 1, Species: 0.035575\n",
      "Average for Cluster 1: 0.035205\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n",
      "Iteration 50:\n",
      "Cluster 0, Family: 0.034464\n",
      "Cluster 0, Genus: 0.035575\n",
      "Cluster 0, Species: 0.035575\n",
      "Average for Cluster 0: 0.035205\n",
      "Cluster 1, Family: 0.432583\n",
      "Cluster 1, Genus: 0.561023\n",
      "Cluster 1, Species: 0.692244\n",
      "Average for Cluster 1: 0.561950\n",
      "Average for iteration: 0.2985772581674484\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_hamming_loss = []\n",
    "\n",
    "for i in range(1,51):\n",
    "    print('Iteration %d:'%(i))\n",
    "    ham_loss = k_means_clustering()\n",
    "    all_hamming_loss.append(ham_loss)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all 50 iterations, the most optimal K was K = 2 which was selected using CH. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average hamming loss for all iterations is: 0.2985772581674484\n",
      "Standard deviation hamming loss for all iterations is: 0.0\n"
     ]
    }
   ],
   "source": [
    "average_hamming = np.mean(np.array(all_hamming_loss))\n",
    "std_hamming = np.std(np.array(all_hamming_loss))\n",
    "print('Average hamming loss for all iterations is:', average_hamming)\n",
    "print('Standard deviation hamming loss for all iterations is:', std_hamming)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
